{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Constants for frame size and overlap\n",
    "N_MFCC = 13\n",
    "N_FFT = 512\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "# Function for denoising using wavelet\n",
    "def denoise_wavelet(audio, threshold=1e-6, preserve_threshold=0.05):\n",
    "    coeffs = pywt.wavedec(audio, 'db1', level=6)\n",
    "    preserved_coeffs = [coeffs[0]]\n",
    "\n",
    "    for i in range(1, len(coeffs)):\n",
    "        thresholded_coeff = pywt.threshold(coeffs[i], threshold, mode='soft')\n",
    "        if np.sum(np.abs(thresholded_coeff)) > preserve_threshold:\n",
    "            preserved_coeffs.append(thresholded_coeff)\n",
    "        else:\n",
    "            preserved_coeffs.append(np.zeros_like(thresholded_coeff))\n",
    "\n",
    "    audio_denoised = pywt.waverec(preserved_coeffs, 'db1')\n",
    "\n",
    "    return audio_denoised\n",
    "\n",
    "# Function to convert audio to digital values\n",
    "def audio_to_digital(audio_file):\n",
    "    audio, sr = librosa.load(audio_file, sr=16000, res_type='kaiser_fast')\n",
    "    digital_values = (audio / np.max(np.abs(audio))) * 1023\n",
    "    return digital_values\n",
    "\n",
    "# Function for audio preprocessing\n",
    "def preprocess_audio(file_path, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    digital_values = audio_to_digital(file_path)\n",
    "    amplitude = digital_values / 1023\n",
    "    audio_denoised = denoise_wavelet(amplitude, preserve_threshold=0.05)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=audio_denoised, sr=16000, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    rmse = librosa.feature.rms(y=audio_denoised, frame_length=n_fft, hop_length=hop_length)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio_denoised, sr=16000, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    mean_mfcc = np.mean(mfccs, axis=1)\n",
    "    mean_rmse = np.mean(rmse)\n",
    "    mean_centroid = np.mean(spectral_centroid)\n",
    "\n",
    "    return mean_mfcc, mean_rmse, mean_centroid\n",
    "\n",
    "# Function to process all audio files in a directory\n",
    "def process_all_files(directory_path):\n",
    "    all_results_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "        if os.path.isfile(file_path) and file_name.endswith('.wav'):\n",
    "            label = 1 if \"scream\" in file_name.lower() else 0\n",
    "\n",
    "            mean_mfcc, mean_rmse, mean_centroid = preprocess_audio(file_path)\n",
    "\n",
    "            result_dict = {\n",
    "                'file': file_name,\n",
    "                'Label': label,\n",
    "                **{f'MFCC_{j}': mean_mfcc[j] for j in range(len(mean_mfcc))},\n",
    "                'Mean Root-Mean-Square Energy': mean_rmse,\n",
    "                'Mean Spectral Centroid': mean_centroid\n",
    "            }\n",
    "            result_df = pd.DataFrame([result_dict])\n",
    "            all_results_df = pd.concat([all_results_df, result_df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            print(f'Skipping non-WAV file: {file_name}')\n",
    "\n",
    "    all_results_df.to_csv('feature_train.csv', index=False)\n",
    "\n",
    "directory_path = 'suara/data/sound/train'\n",
    "process_all_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import os\n",
    "\n",
    "# Constants for frame size and overlap\n",
    "N_MFCC = 13\n",
    "N_FFT = 512\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "# Function for denoising using wavelet\n",
    "def denoise_wavelet(audio, threshold=1e-6, preserve_threshold=0.05):\n",
    "    coeffs = pywt.wavedec(audio, 'db1', level=6)\n",
    "    preserved_coeffs = [coeffs[0]]\n",
    "\n",
    "    for i in range(1, len(coeffs)):\n",
    "        thresholded_coeff = pywt.threshold(coeffs[i], threshold, mode='soft')\n",
    "        if np.sum(np.abs(thresholded_coeff)) > preserve_threshold:\n",
    "            preserved_coeffs.append(thresholded_coeff)\n",
    "        else:\n",
    "            preserved_coeffs.append(np.zeros_like(thresholded_coeff))\n",
    "\n",
    "    audio_denoised = pywt.waverec(preserved_coeffs, 'db1')\n",
    "\n",
    "    return audio_denoised\n",
    "\n",
    "# Function to convert audio to digital values\n",
    "def audio_to_digital(audio_file):\n",
    "    audio, sr = librosa.load(audio_file, sr=16000, res_type='kaiser_fast')\n",
    "    digital_values = (audio / np.max(np.abs(audio))) * 1023\n",
    "    return digital_values\n",
    "\n",
    "# Function for audio preprocessing\n",
    "def preprocess_audio(file_path, n_mfcc=N_MFCC, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    digital_values = audio_to_digital(file_path)\n",
    "    amplitude = digital_values / 1023\n",
    "    audio_denoised = denoise_wavelet(amplitude, preserve_threshold=0.05)\n",
    "\n",
    "    mfccs = librosa.feature.mfcc(y=audio_denoised, sr=16000, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "    rmse = librosa.feature.rms(y=audio_denoised, frame_length=n_fft, hop_length=hop_length)\n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=audio_denoised, sr=16000, n_fft=n_fft, hop_length=hop_length)\n",
    "\n",
    "    mean_mfcc = np.mean(mfccs, axis=1)\n",
    "    mean_rmse = np.mean(rmse)\n",
    "    mean_centroid = np.mean(spectral_centroid)\n",
    "\n",
    "    return mean_mfcc, mean_rmse, mean_centroid\n",
    "\n",
    "# Function to process all audio files in a directory\n",
    "def process_all_files(directory_path):\n",
    "    all_results_df = pd.DataFrame()\n",
    "\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "\n",
    "        if os.path.isfile(file_path) and file_name.endswith('.wav'):\n",
    "            label = 1 if \"scream\" in file_name.lower() else 0\n",
    "\n",
    "            mean_mfcc, mean_rmse, mean_centroid = preprocess_audio(file_path)\n",
    "\n",
    "            result_dict = {\n",
    "                'file': file_name,\n",
    "                'Label': label,\n",
    "                **{f'MFCC_{j}': mean_mfcc[j] for j in range(len(mean_mfcc))},\n",
    "                'Mean Root-Mean-Square Energy': mean_rmse,\n",
    "                'Mean Spectral Centroid': mean_centroid\n",
    "            }\n",
    "            result_df = pd.DataFrame([result_dict])\n",
    "            all_results_df = pd.concat([all_results_df, result_df], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            print(f'Skipping non-WAV file: {file_name}')\n",
    "\n",
    "    all_results_df.to_csv('feature_val.csv', index=False)\n",
    "\n",
    "directory_path = 'suara/data/sound/val'\n",
    "process_all_files(directory_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
